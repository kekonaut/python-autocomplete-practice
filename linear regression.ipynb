{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACpRJREFUeJzt3f9rXfUdx/HXa1HZnM5A2xVp6tIfpCCDpRIK0iGu4qhTtD/shxYUIoP+pDRsILrf9g9I98MQpOoKdspWFUWcTtDghM2Z1nSzTTu6ktIUXVNG8RusVN/7IadQpSMnvZ9zzr1vng8I5iaXfN6X8vSce3NzPo4IAcjpG10PAKA5BA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYlc08UNXrlwZo6OjTfxoNGRubq61tT7//PPW1lqxYkVra0nS6tWrW1lnbm5OZ86c8VL3ayTw0dFRTU9PN/Gj0ZCJiYnW1pqZmWltrTYflyRNTk62ss74+Hit+3GKDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBitQK3vcX2UdvHbD/S9FAAylgycNtDkn4j6U5JN0nabvumpgcD0Ls6R/CNko5FxPGIOCfpOUn3NjsWgBLqBL5G0smLbs9XXwPQ54q9yGZ7h+1p29MLCwulfiyAHtQJ/JSktRfdHqm+9hUR8UREjEfE+KpVq0rNB6AHdQJ/T9KNttfZvkrSNkkvNzsWgBKW/HvwiDhv+0FJr0sakvRURBxqfDIAPat1wYeIeFXSqw3PAqAw3skGJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGKN7GyCMl566aXW1tqzZ09ra7Vpamqq1fXa2tmkLo7gQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBidXY2ecr2adsftDEQgHLqHMF/K2lLw3MAaMCSgUfE25L+08IsAArjOTiQGFsXAYkVC5yti4D+wyk6kFidX5M9K+kvktbbnrf9s+bHAlBCnb3JtrcxCIDyOEUHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDG2LlqGtrfB2blzZ6vrZXTbbbd1PUKnOIIDiRE4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJBYnYsurrX9lu3Dtg/Z5v2TwICo817085J+EREHbF8rab/tNyLicMOzAehRnb3JPoyIA9Xnn0ialbSm6cEA9G5Zz8Ftj0raIOndS3yPrYuAPlM7cNvXSHpe0mREfPz177N1EdB/agVu+0otxr03Il5odiQApdR5Fd2SnpQ0GxGPNT8SgFLqHME3Sbpf0mbbM9XHTxqeC0ABdfYme0eSW5gFQGG8kw1IjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxAZ+b7KZmZnW1pqYmGhtLUk6ceJEq+tlNDY21vUIneIIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kVueii9+0/TfbB6uti37VxmAAelfnrar/lbQ5Ij6tLp/8ju0/RsRfG54NQI/qXHQxJH1a3byy+ogmhwJQRt2ND4Zsz0g6LemNiGDrImAA1Ao8Ir6IiDFJI5I22v7+Je7D1kVAn1nWq+gRcVbSW5K2NDMOgJLqvIq+yvZw9fm3JN0h6UjTgwHoXZ1X0a+XtMf2kBb/h/D7iHil2bEAlFDnVfS/a3FPcAADhneyAYkROJAYgQOJETiQGIEDiRE4kBiBA4kROJDYwG9dNDU11dpabCWEQcMRHEiMwIHECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIrHbg1bXR37fN9diAAbGcI/hOSbNNDQKgvLo7m4xIukvS7mbHAVBS3SP4LkkPS/qywVkAFFZn44O7JZ2OiP1L3I+9yYA+U+cIvknSPbbnJD0nabPtZ75+J/YmA/rPkoFHxKMRMRIRo5K2SXozIu5rfDIAPeP34EBiy7qiS0RMSZpqZBIAxXEEBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCCxgd+6aHJysrW1tm7d2tpaba938ODB1tZq0/DwcNcjdIojOJAYgQOJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQWK13slVXVP1E0heSzkfEeJNDAShjOW9V/VFEnGlsEgDFcYoOJFY38JD0J9v7be9ociAA5dQ9Rf9hRJyy/V1Jb9g+EhFvX3yHKvwdknTDDTcUHhPA5ah1BI+IU9V/T0t6UdLGS9yHrYuAPlNn88Fv2772wueSfizpg6YHA9C7OqfoqyW9aPvC/X8XEa81OhWAIpYMPCKOS/pBC7MAKIxfkwGJETiQGIEDiRE4kBiBA4kROJAYgQOJETiQ2MBvXdSm0dHRtOtl3bpobGys6xE6xREcSIzAgcQIHEiMwIHECBxIjMCBxAgcSIzAgcQIHEisVuC2h23vs33E9qztW5oeDEDv6r5V9deSXouIn9q+StLVDc4EoJAlA7d9naRbJU1IUkSck3Su2bEAlFDnFH2dpAVJT9t+3/bu6vroAPpcncCvkHSzpMcjYoOkzyQ98vU72d5he9r29MLCQuExAVyOOoHPS5qPiHer2/u0GPxXsHUR0H+WDDwiPpJ00vb66ku3Szrc6FQAiqj7KvpDkvZWr6Afl/RAcyMBKKVW4BExI2m84VkAFMY72YDECBxIjMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxNibrI/t2rWrtbXm5uZaW6vNfdDOnj3b2lqSNDw83Op6S+EIDiRG4EBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4ktmTgttfbnrno42Pbk20MB6A3S75VNSKOShqTJNtDkk5JerHhuQAUsNxT9Nsl/SsiTjQxDICylhv4NknPXuobbF0E9J/agVebHtwj6Q+X+j5bFwH9ZzlH8DslHYiIfzc1DICylhP4dv2f03MA/alW4NV+4HdIeqHZcQCUVHdvss8krWh4FgCF8U42IDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxJzRJT/ofaCpOX+SelKSWeKD9Mfsj42Hld3vhcRS/5VVyOBXw7b0xEx3vUcTcj62Hhc/Y9TdCAxAgcS66fAn+h6gAZlfWw8rj7XN8/BAZTXT0dwAIX1ReC2t9g+avuY7Ue6nqcE22ttv2X7sO1Dtnd2PVNJtodsv2/7la5nKcn2sO19to/YnrV9S9cz9aLzU/TqWuv/1OIVY+YlvSdpe0Qc7nSwHtm+XtL1EXHA9rWS9kvaOuiP6wLbP5c0Luk7EXF31/OUYnuPpD9HxO7qQqNXR8TZrue6XP1wBN8o6VhEHI+Ic5Kek3RvxzP1LCI+jIgD1eefSJqVtKbbqcqwPSLpLkm7u56lJNvXSbpV0pOSFBHnBjluqT8CXyPp5EW355UkhAtsj0raIOndbicpZpekhyV92fUgha2TtCDp6erpx+7qeoQDqx8CT832NZKelzQZER93PU+vbN8t6XRE7O96lgZcIelmSY9HxAZJn0ka6NeE+iHwU5LWXnR7pPrawLN9pRbj3hsRWa5Iu0nSPbbntPh0arPtZ7odqZh5SfMRceFMa58Wgx9Y/RD4e5JutL2uelFjm6SXO56pZ7atxedysxHxWNfzlBIRj0bESESMavHf6s2IuK/jsYqIiI8knbS9vvrS7ZIG+kXRWpdNblJEnLf9oKTXJQ1JeioiDnU8VgmbJN0v6R+2Z6qv/TIiXu1wJiztIUl7q4PNcUkPdDxPTzr/NRmA5vTDKTqAhhA4kBiBA4kROJAYgQOJETiQGIEDiRE4kNj/AF3Zo6E8LtkPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader, random_split\n",
    "%matplotlib inline\n",
    "\n",
    "X, y = ds.load_digits(n_class=2, return_X_y=True)\n",
    "plt.imshow(X[50].reshape((8, 8)), cmap='binary')\n",
    "l = len(X)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Переводим данные в тензоры. Разбиваем на обучающую, тестовую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = torch.LongTensor(X)\n",
    "y = torch.LongTensor(y)\n",
    "data = TensorDataset(X, y)\n",
    "train_data, test_data, val_data = random_split(data, [int(l * 0.7), int(l * 0.2), l - int(l * 0.7) - int(l * 0.2)])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    ".................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lin(torch.nn.Module):\n",
    "    def __init__(self, input):\n",
    "        super(Lin, self).__init__()\n",
    "        self.linear = nn.Linear(input, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.nn.Sigmoid(self.linear(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "input = 8 * 8\n",
    "#output = 2\n",
    "model = Lin(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-3b064c037fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch = {epoch}, acc = {acc}, loss = {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-113-3b064c037fed>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, test_data, val_data, max_epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-4f4ca2f6d669>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def train_model(model, train_data, test_data, val_data, max_epochs=30):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=20, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=20, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=30, shuffle=True)\n",
    "    for epoch in range(max_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch.float())\n",
    "            loss = nn.CrossEntropyLoss(y_pred, y_batch)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 3 == 2:\n",
    "                acc = correct / total\n",
    "                print(f'Epoch = {epoch}, acc = {acc}, loss = {loss}')\n",
    "\n",
    "train_model(model, train_data, test_data, val_data, max_epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
