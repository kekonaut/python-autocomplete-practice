{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "%matplotlib inline\n",
    "\n",
    "X, y = ds.load_digits(n_class=2, return_X_y=True)\n",
    "plt.imshow(X[50].reshape((8, 8)), cmap='binary')\n",
    "l = len(X)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Переводим данные в тензоры. Разбиваем на обучающую, тестовую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = torch.LongTensor(X)\n",
    "y = torch.LongTensor(y)\n",
    "data = TensorDataset(X, y)\n",
    "train_data, test_data, val_data = random_split(data, [int(l * 0.7), int(l * 0.2), l - int(l * 0.7) - int(l * 0.2)])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Создаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Lin(torch.nn.Module):\n",
    "    def __init__(self, input):\n",
    "        super(Lin, self).__init__()\n",
    "        self.linear = nn.Linear(input, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.linear(x))\n",
    "        return out\n",
    "\n",
    "\n",
    "input = 8 * 8\n",
    "#output = 2\n",
    "model = Lin(input)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(model, val_data):\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=10, shuffle=True)\n",
    "    model = model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        y_pred = model(X_batch.float())\n",
    "        total += y_batch.size(0)\n",
    "        correct += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 2, acc = 1.0, loss = 0.3133995234966278\nVAL:  Epoch = 2,acc =1.0 \nEpoch = 5, acc = 1.0, loss = 0.31327417492866516\nVAL:  Epoch = 5,acc =1.0 \nEpoch = 8, acc = 1.0, loss = 0.31330132484436035\nVAL:  Epoch = 8,acc =1.0 \nEpoch = 11, acc = 1.0, loss = 0.31335604190826416\nVAL:  Epoch = 11,acc =1.0 \nEpoch = 14, acc = 1.0, loss = 0.31329789757728577\nVAL:  Epoch = 14,acc =1.0 \nEpoch = 17, acc = 1.0, loss = 0.3132680654525757\nVAL:  Epoch = 17,acc =1.0 \nEpoch = 20, acc = 1.0, loss = 0.3132648766040802\nVAL:  Epoch = 20,acc =1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 23, acc = 1.0, loss = 0.3132656514644623\nVAL:  Epoch = 23,acc =1.0 \nEpoch = 26, acc = 1.0, loss = 0.31327563524246216\nVAL:  Epoch = 26,acc =1.0 \nEpoch = 29, acc = 1.0, loss = 0.31343552470207214\nVAL:  Epoch = 29,acc =1.0 \nEpoch = 32, acc = 1.0, loss = 0.31326889991760254\nVAL:  Epoch = 32,acc =1.0 \nEpoch = 35, acc = 1.0, loss = 0.3132665753364563\nVAL:  Epoch = 35,acc =1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 38, acc = 1.0, loss = 0.31326717138290405\nVAL:  Epoch = 38,acc =1.0 \nEpoch = 41, acc = 1.0, loss = 0.31329023838043213\nVAL:  Epoch = 41,acc =1.0 \nEpoch = 44, acc = 1.0, loss = 0.31327322125434875\nVAL:  Epoch = 44,acc =1.0 \nEpoch = 47, acc = 1.0, loss = 0.3132726550102234\nVAL:  Epoch = 47,acc =1.0 \nEpoch = 50, acc = 1.0, loss = 0.3132655918598175\nVAL:  Epoch = 50,acc =1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 53, acc = 1.0, loss = 0.313280314207077\nVAL:  Epoch = 53,acc =1.0 \nEpoch = 56, acc = 1.0, loss = 0.31329554319381714\nVAL:  Epoch = 56,acc =1.0 \nEpoch = 59, acc = 1.0, loss = 0.31327617168426514\nVAL:  Epoch = 59,acc =1.0 \nEpoch = 62, acc = 1.0, loss = 0.3132759630680084\nVAL:  Epoch = 62,acc =1.0 \nEpoch = 65, acc = 1.0, loss = 0.3132672607898712\nVAL:  Epoch = 65,acc =1.0 \nEpoch = 68, acc = 1.0, loss = 0.3132699728012085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL:  Epoch = 68,acc =1.0 \nEpoch = 71, acc = 1.0, loss = 0.31335198879241943\nVAL:  Epoch = 71,acc =1.0 \nEpoch = 74, acc = 1.0, loss = 0.31326958537101746\nVAL:  Epoch = 74,acc =1.0 \nEpoch = 77, acc = 1.0, loss = 0.3133503198623657\nVAL:  Epoch = 77,acc =1.0 \nEpoch = 80, acc = 1.0, loss = 0.31326788663864136\nVAL:  Epoch = 80,acc =1.0 \nEpoch = 83, acc = 1.0, loss = 0.31326916813850403\nVAL:  Epoch = 83,acc =1.0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 86, acc = 1.0, loss = 0.31328845024108887\nVAL:  Epoch = 86,acc =1.0 \nEpoch = 89, acc = 1.0, loss = 0.3133159577846527\nVAL:  Epoch = 89,acc =1.0 \nEpoch = 92, acc = 1.0, loss = 0.31336167454719543\nVAL:  Epoch = 92,acc =1.0 \nEpoch = 95, acc = 1.0, loss = 0.3132869005203247\nVAL:  Epoch = 95,acc =1.0 \nEpoch = 98, acc = 1.0, loss = 0.3133905231952667\nVAL:  Epoch = 98,acc =1.0 \n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_data, val_data, max_epochs=100):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=20, shuffle=True)\n",
    "    for epoch in range(max_epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model = model.train()\n",
    "            y_pred = model(X_batch.float())\n",
    "            loss1 = loss(y_pred, y_batch)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if epoch % 3 == 2:\n",
    "            acc = correct / total\n",
    "            print(f'Epoch = {epoch}, acc = {acc}, loss = {loss1}')\n",
    "            print(f'VAL:  Epoch = {epoch},acc ={Validate(model,val_data)} ')\n",
    "train_model(model, train_data, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
